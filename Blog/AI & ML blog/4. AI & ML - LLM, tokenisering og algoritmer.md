
## Mål for etapen.
At gå i lidt i dybden med tokenisering og opnå noget forståelse omrking LLM modellers træning og forståelse af materiale og hvilke forskelle 

---

##  Hvad jeg lærte
Jeg kiggede på tokenisering og tokeniserings algoritmer og fik et indblik i Byte pr side og wordpiece samt lidt om subword tokenisering.  og hvordan det bruges af AI modellerne til at opdele tekster i tokens på forskellige måder alt efter modeller.
Det er stadigvæk kun et indblik i algoritmerne og jeg er lidt i tvivl om jeg har behov for at gå meget mere i dybden. Jeg vil dog arbejde med emner i min gennemgang og tilegne mig en forståelse da jeg tænker det giver et godt fundament for mit arbejde med AI og forståelsen af modellerne og deres forskelle :

[[Tokenisering og træning]]

##  Refleksion
Der er forskel på modellernes evner og hvor de kan bruges bedst. fx. er der alt efter materialet forskel på hvor gode de til sundhedsrelevant data alt efter algoritmer de er bygget op omkring, hvilket også har relevans i forhold til visse sprog. 


## Projekt specifikt. 
Her er der kommet flere detaljer på omkring scope og der er blevet ændret lidt i kravene. Så scope er noget mindre, og der bliver ikke brug for flere databaser samt microservices i dette projekt.

Det er relevant at få fulgt op på hvilke modeller der bedst muligt dækker behovene for vores projekt og forståelsen af sundhedsdata der skal indhentes og tages hensyn til i svarene. 
Det vil jeg kigge yderligere på over tid. Det er dog vigtigt for min chatbot at den fungerer på et acceptabelt niveau og at det foregår forholdvist hurtigt.
Det er tit meget lavt niveau og til tider er der meget latenc på modellernes svar på div. virksomhedessider der har en lille mini chatbot guide.
