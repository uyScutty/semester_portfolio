

##  M√•l for etapen
At starte op p√• l√¶ring omkring RAG VS. Fine tuning for at fors√• hvad der specifikt g√∏r sig bedst g√¶ldende for vores 3 brug scenarier af LLM modeller. 
Lave videre p√• projekter i python og opn√• st√∏rre praktisk forst√•else for hvad en AI-chatbot skal indeholde og kunne og hvordan det fungerer.
Hvordan den g√∏r brug af vector og persistens. Det er en forts√¶ttelse af f√∏rste projekt.

---

## üìö Hvad jeg l√¶rte

Retrieval Argumented Generation (RAG) er en metode hvor der gennemg√•s lokale data for informationer og oplysninger, inden der genereres et svar p√• en foresp√∏rgsel af LLM modellen.
Her kan der fx. bruges Few Shot Prompting, hvor der er gennemg√•es en r√¶kke svarmuligheder for at generere det bedst mulige svar.
At fine tuning ligesom RAG giver en god mulighed for at p√•virke LLM modellens output til en specifik foresp√∏rgsel. Her skal den dog tr√¶nes.
[[RAG VS. Finetuning]]
Jeg har arbejdet med projektet og lavet f√∏rste simple del via huggingface biblioteket.
[[Chatbot i Python test 1. ( Setup & in memory vector s√∏gning)]]

Derudover har jeg arbejdet med et andet projekt:
[[Chatbot i python test 2. (Persitens)]]
---
Samtidig begyndte jeg at arbejde videre med RAG i Python-projektet.  
Her er forskellen tydelig: i stedet for at tr√¶ne modellen om, s√• henter RAG relevante tekststykker fra mine dokumenter og bruger dem som kontekst.

Jeg pr√∏vede f√∏rst at s√¶tte persistens op med Chroma, men det gik ikke s√• nemt, s√• skiftede jeg til FAISS, som fungerede med det samme.

FAISS virker hurtigere og mere stabilt i denne ops√¶tning, og det g√∏r egentlig ikke s√• meget, at det ikke har ‚Äúindbygget‚Äù persistens p√• samme m√•de.  
Jeg kan stadig gemme embeddings manuelt og loade dem igen og f√• noget praktisk "hands on" erfarring med persistens

## üí° Refleksion

Det vil give god mening at g√∏re brug af RAG i de tilf√¶lde hvor der er en stor m√¶ngde dom√¶ne specifikke data der skal gennemg√•es og danne grundlag for et svar til brugeren. Hvis der skal tages ekstra hensyn til en specifik vinkel og modellen skal ledes i en given retning f√∏r den genererer sit svar.
At fine tuning virker til at v√¶re en lidt mere kompleks process i forhold til RAG og det kan kr√¶ve lidt mere arbejde at tilpasse modellen.

üí° Projekt specifikt. 
Her er det oplagt mulighed at bruge RAG til at opstille en r√¶kke relevante data, som der kan danne grundlag for svaret. Da det er en helt speciel vinkel og specifikke hensyn vores PO √∏nsker tr√¶der i kraft n√•r svaret genereres til brugeren. Der skal dog bruges flere modeller/agenter i vores projekt og det kan derfor v√¶re relevant med andre metoder istedet.