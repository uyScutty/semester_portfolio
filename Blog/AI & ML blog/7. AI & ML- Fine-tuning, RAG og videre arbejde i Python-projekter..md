
##  Mål for etapen

I denne etape ville jeg gå mere i dybden med fine-tuning og samtidig få et samlet overblik over forskellene mellem RAG og fine-tuning.  
Derudover begyndte jeg at arbejde mere praktisk i mit Python-projekt, hvor jeg fik sat persistens op.


---

##  Hvad jeg lærte

Fine-tuning er en måde at træne en eksisterende base-model videre på med specifikt materiale.  
Det betyder, at modellen ikke kun lærer selve indholdet, men også den måde svarene skal struktureres på inden for det pågældende område.

Jeg forstår det som en slags undervisningsproces:

- Modellen bliver præsenteret for spørgsmål og svar
- Gode svar bliver “belønnet” og Dårlige svar bliver “straffet”
- Og over tid lærer den at ramme den stil og retning, man ønsker

Det er en omfattende proces, især hvis der er meget materiale, eller hvis modellen ofte skal opdateres.  
Til gengæld kan det give en meget stabil og ensartet måde at svare på, især hvis man har en agent med faste mønstre.

---

##  RAG i praksis – Chroma til FAISS

Samtidig begyndte jeg at arbejde videre med RAG i Python-projektet.  
Her er forskellen tydelig: i stedet for at træne modellen om, så henter RAG relevante tekststykker fra mine dokumenter og bruger dem som kontekst.

Jeg prøvede først at sætte persistens op med Chroma, men det gik ikke så nemt, så skiftede jeg til FAISS, som fungerede med det samme.

FAISS virker hurtigere og mere stabilt i denne opsætning, og det gør egentlig ikke så meget, at det ikke har “indbygget” persistens på samme måde.  
Jeg kan stadig gemme embeddings manuelt og loade dem igen og få noget praktisk "hands on" erfarring med persistens

[[Chatbot i python test 2. (Persistens)]]
---

##  Refleksion

Det står klart for mig, at finetuning er en tungere proces end RAG, og at det kræver mere at holde ved lige. Derfor giver det ikke mening at bruge det alle steder i projektet.  
Men jeg kan også se, at finetuning kan være en fordel, når man har meget faste typer svar eller en bestemt struktur, der skal gentages hver gang.

Det er her vores  agent kunne begynde at give mening via finetuning. Research agenten til PO kunnne gøre brug af finetuning. 
Hvis den skal generere faste typer planer, ugestrukturer eller regler, kunne den på sigt have gavn af en lille finetuning, fordi den så lærer, hvordan en “rigtig” plan skal se ud — og ikke kun hvilke informationer den skal bruge.

Omvendt giver det stadig mest mening at fortsætte med RAG i min cahtbot implmentering.
Den ene chatbot der guider brugeren rundt på siden, og den anden chatbot der svarer ud fra sundhedsrelateret indhold.  
Her ændrer vores tekster sig ofte, og modellen skal kunne hente den nyeste viden direkte fra dokumenterne, hvilket RAG er perfekt til.

