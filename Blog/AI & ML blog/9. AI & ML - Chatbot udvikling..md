# Projekt 4-5 – Fra ren RAG til en agent.

## Mål for etapen

Her er planen at opnå generative AI via agentens svar til brugeren.
Derefter skal der startes et nyt projekt op der skal være grundlaget for min implmenattion af en chatagent til projektet. 
Her vil jeg gå fra lokal AI model til OpenaAI som den tilkoblede AI model. 

- At bruge data fra Thewayofcoherenceprojektets oprindelige side og lave (FAISS + embeddings) på den data der skal bruges til det endelige projekt
- Lade RAG finde de rigtige dokumenter.
- sende de fundne dokumenter videre til en LLM.
- Og få modellen til at skrive selve svaret, baseret på præcis den kontekst jeg giver den.
- Derudover skal AI modellen svare ud fra dens rolle og med specificeret instrukser.
   
**RAG + generativ AI = en rigtig agent**, ikke bare en søgerobot.

---

### Hvad jeg lærte

Det sjove ved den her etape var, hvor tydeligt det pludselig blev, hvor forskelligt systemet arbejder:

Og jeg fik også en vigtig erfaring:  
En LLM svarer ikke nødvendigvis ud fra dine dokumenter, medmindre du _styrer prompten meget præcist_.  
Derfor byggede jeg en structured prompt, hvor jeg:

- indsatte de fundne tekster
- gav en rolle (“rolig, hjælpsom guide”)
- satte regler (“brug kun denne kontekst, ingen medicinske råd, ingen faktaopfindelser”)
Det gjorde en verden til forskel, så nu holdt modellen sig til min videnbase – ikke intern viden eller gæt.
Det gør en stor forskel at modellen får "instruction-tuning" og regler for dens rolle.
se [[Chatbot test 5 Fra chatbot på vej mod agent - Foundation spikeprojekt med RAG & Ekstern LLM]]
## Refleksion


Jeg har nu en klar praktisk ide om, hvordan den endelige prototype vil se ud, med regler og instrukser, der kan styre dens ageren og opførsel som guide på hjemmesiden og jeg ser frem til at lave det sidste færdigt og få arbejdet med den endelige model og dens detaljer.