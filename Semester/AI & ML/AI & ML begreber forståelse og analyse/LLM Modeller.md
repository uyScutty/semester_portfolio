# **Blog â€“ Etape: LLM-modeller og deres styrker, svagheder og anvendelse**

## ğŸ¯ MÃ¥l for etapen

Jeg ville i denne etape skabe et overblik over forskellige LLM-modeller og forstÃ¥, hvad de hver isÃ¦r er gode til.  
Det er vigtigt i forhold til projektet, fordi vores tre chatagenter kan have forskellige behov, bÃ¥de i forhold til sprog, domÃ¦ne, pris og prÃ¦cision.

---

## ğŸ“š Hvad jeg lÃ¦rte

Jeg er stÃ¸dt pÃ¥ en del forskellige modeller efterhÃ¥nden, og det er blevet tydeligt for mig, at de ikke fungerer ens. BÃ¥de deres arkitektur, stÃ¸rrelse, trÃ¦ningsdata og tokenisering gÃ¸r en forskel.

Her er et samlet overblik over de modeller, jeg har arbejdet med eller lÃ¦rt om indtil nu:

---

### ğŸ”¹ **OpenAI (GPT-modellerne)**

OpenAI-modellerne er meget stÃ¦rke generelle modeller. De er gode til:

- formidling
    
- forklaringer
    
- logik
    
- generering af lÃ¦ngere svar
    

De hÃ¥ndterer det meste rigtig godt, men de er ogsÃ¥ de dyreste at bruge.  
Til gengÃ¦ld er de stabile og pÃ¥lidelige, og de fungerer rigtig godt til sprog som dansk og engelsk.

---

### ğŸ”¹ **Claude (Anthropic)**

Claude er isÃ¦r god til lange dokumenter og komplekse sammenhÃ¦nge. Den har et meget stort kontekstvindue og gode evner til at bevare struktur i lÃ¦ngere svar.

Den virker ogsÃ¥ rigtig god til opsummering og at holde styr pÃ¥ detaljer.  
Den kan dog vÃ¦re lidt dyrere, og jeg er ikke sikker pÃ¥ hvor god den er pÃ¥ meget domÃ¦nespecifik sundhedsdata.

---

### ğŸ”¹ **DeepSeek**

DeepSeek-modellerne er open-source og gratis, og de overraskede mig positivt.  
De virker stÃ¦rke til logik, reasoning og isÃ¦r kodning.  
De kan godt vÃ¦re lidt mere ustabile i svarene, men til gengÃ¦ld er de Ã¸konomisk rigtig gode, og de kan kÃ¸re lokalt.

Til projektet giver DeepSeek mest mening i udviklingsfasen og prototyper, men mÃ¥ske ikke som primÃ¦r sundhedsagent.

---

### ğŸ”¹ **Llama / Mistral / Gemma (open-source modeller)**

Disse modeller er gratis og kan kÃ¸re lokalt via fx Ollama.  
De er rigtig gode, hvis man vil have fuld kontrol, lave test, eller bygge noget der ikke skal koste penge i API-kald.

De kan dog variere meget i kvalitet, isÃ¦r pÃ¥ dansk og sundhedsrelaterede emner.  
Men nogle af dem (fx Mistral) er blevet meget stÃ¦rke i almindelig generering.

---

### ğŸ”¹ **BERT og lignende encoder-modeller**

BERT er en helt anden type model, som jeg har lÃ¦rt bruges primÃ¦rt til:

- klassifikation
    
- forstÃ¥else
    
- sÃ¸gning
    
- embeddings
    

Den genererer ikke svar og er ikke en chatbot.  
Men den er vigtig i RAG-systemer, fordi encoder-modeller bruges til at generere embeddings.  
Det gÃ¸r den indirekte relevant for mit Python-projekt.

---

## ğŸ’¡ Refleksion

NÃ¥r jeg ser pÃ¥ alle modellerne samlet, giver det mere mening for mig, hvorfor man ikke bare kan â€œvÃ¦lge en tilfÃ¦ldig LLMâ€.  
Der er forskelle i:

- hvor gode de er til dansk
    
- hvor dybe deres svar er
    
- om de er gode til sundhedsrelevante spÃ¸rgsmÃ¥l
    
- hvor dyre de er at bruge
    
- om de kan kÃ¸re lokalt
    
- og hvor stabile de er
    

OpenAI og Claude virker som stÃ¦rke valg til en sundheds- eller informationsagent, fordi de har stabilitet, sprogforstÃ¥else og gode forklaringer.  
DeepSeek og open-source modellerne virker bedre som udviklingsvÃ¦rktÃ¸jer eller billige alternativer, men mÃ¥ske ikke til det mest fÃ¸lsomme indhold.

---

## ğŸ’¡ Projekt specifikt

Jeg kan allerede se, at vores tre chatagenter mÃ¥ske ender med at bruge forskellige modeller â€“ eller i hvert fald have forskellige styrker.

- **Guider-agenten** vil drage fordel af stabile modeller, der kan forklare ting klart.
    
- **Sundhedsagenten** krÃ¦ver en model, der er god til at forstÃ¥ fagtermer og som giver mindre risiko for fejl.
    
- **TrÃ¦ningsplan-agenten** skal nok bruge en model, der kan generere strukturerede svar, og her kan finetuning komme pÃ¥ tale.
    

Det er tydeligt for mig, at modelvalg hÃ¦nger sammen med bÃ¥de RAG, tokenisering, transformer-arkitekturen og den mÃ¥de jeg bygger Python-projektet pÃ¥.  
Det hele begynder at hÃ¦nge sammen nu, og jeg fÃ¸ler, at jeg har fÃ¥et en mere realistisk forstÃ¥else af forskellene mellem modellerne og deres styrker i praksis