# **LÃ¦ringsside â€“ Uddybning til Etape â€œRAG vs. Fine-tuningâ€**

_(skrevet som om det er dig, i samme tone som dine Ã¸vrige blogs)_

---

## ğŸ” Min uddybede forstÃ¥else af RAG og Fine-tuning

I denne etape begyndte jeg at arbejde mere konkret med forskellen mellem RAG og fine-tuning, og hvad der faktisk giver mening i forhold til de tre forskellige agenter vi skal bygge i projektet. Det blev hurtigt tydeligt for mig, at selvom begge begreber ofte nÃ¦vnes sammen, sÃ¥ lÃ¸ser de to ting meget forskellige problemer â€“ og har meget forskellige fordele.

---

## ğŸ§  RAG â€“ det jeg arbejder mest med

RAG (Retrieval Augmented Generation) er i bund og grund en tilgang hvor modellen ikke kun baserer sit svar pÃ¥ det, den allerede er trÃ¦net pÃ¥, men ogsÃ¥ pÃ¥ ny information, som jeg giver den via lokale dokumenter.

Processen i RAG har jeg efterhÃ¥nden fÃ¥et godt styr pÃ¥:

1. Brugeren spÃ¸rger om noget
    
2. Der hentes relevante tekststykker fra mine egne dokumenter (via embeddings og vector-database)
    
3. Disse tekststykker bliver sendt ind som kontekst
    
4. Modellen svarer ud fra bÃ¥de prompten _og_ de dokumenter jeg har valgt
    

Det er ogsÃ¥ denne tilgang, jeg arbejder med i mit Python-projekt lige nu â€“ hvor jeg bruger Chroma som vektor-database og embeddings til at finde relevant viden.  
Jeg bruger ogsÃ¥ few-shot prompting til at styre tonen og formen pÃ¥ svarene.

Det er en fleksibel lÃ¸sning, fordi jeg kan opdatere alt indholdet nÃ¥r som helst, uden at skulle trÃ¦ne en model om.

---

## ğŸ§ª Fine-tuning â€“ forstÃ¥et i forhold til mit projekt

Fine-tuning er en anden tilgang, hvor man tager en eksisterende model og trÃ¦ner den videre pÃ¥ specifik data.  
Modellen Ã¦ndrer sig altsÃ¥ reelt, nÃ¥r man fine-tuner den.

Det giver fordele ved:

- meget faste opgaver
    
- specifik skrivestil
    
- gentagne formater
    
- klassifikationsopgaver
    

Men i mit projekt er behovet noget andet.  
Jeg har mange tekster, der Ã¦ndrer sig over tid, og tre forskellige chatagenter, der hver isÃ¦r skal kunne hÃ¥ndtere bÃ¥de generelle og domÃ¦nespecifikke spÃ¸rgsmÃ¥l.  
Hvis jeg skulle fine-tune, skulle jeg gentage processen hver gang jeg opdaterer viden, og det giver ikke mening i mit setup.

Det blev derfor tydeligere for mig, at fine-tuning ikke rigtig lÃ¸ser det behov jeg har.  
Til gengÃ¦ld kan jeg godt bruge few-shot prompting til at styre stil og svar uden at skulle trÃ¦ne modellen.

---

## ğŸ©º Relevans for de tre agenter i projektet

NÃ¥r jeg kobler RAG og fine-tuning sammen med mine konkrete scenarier, giver det her billede:

### **1) Sundhedsagenten**

Skal kunne trÃ¦kke korrekt viden fra mange tekster.  
Det er helt oplagt at bruge RAG her, sÃ¥ svarene bygger pÃ¥ dokumenterne og ikke pÃ¥ modellens egne gÃ¦t.

### **2) Den halvspecialiserede agent**

Fx til velvÃ¦re, coaching eller lignende.  
Her kan jeg genbruge RAG-modellen og bare tilfÃ¸je nye dokumenter.

### **3) Navigationsagenten (den jeg selv har ansvar for)**

Denne agent skal kunne pege brugeren rundt pÃ¥ siden og forklare indholdet.  
Teksterne vil Ã¦ndre sig lÃ¸bende, og derfor er RAG langt mere fleksibel end fine-tuning.

---

## ğŸ¯ Min egen konklusion

Efter at have arbejdet med begge metoder â€“ og isÃ¦r efter at have implementeret dele af RAG selv â€“ giver det mest mening at fortsÃ¦tte pÃ¥ den vej.  
Fine-tuning virker som en stÃ¸rre og tungere proces, og den lÃ¸ser ikke noget, jeg ikke allerede kan gÃ¸re med:

- RAG
    
- fÃ¥-shot prompts
    
- god kontekst
    
- embeddings
    
- og opdaterbare dokumenter
    

Derfor giver RAG mest mening til alle tre agenttyper i projektet, og det er ogsÃ¥ den tilgang jeg fortsÃ¦tter med i mit Python-projekt.