
# Persistent Vector Store

FormÃ¥l:  
At gÃ¸re dine embeddings permanente, sÃ¥ de ikke forsvinder nÃ¥r programmet stopper â€” i modsÃ¦tning til Projekt 2, som kÃ¸rte â€œin-memoryâ€.

her vil vi:
- FAISS index i RAM
- Gemmer index pÃ¥ disk (`faiss_index.idx`)
- Gemmer metadata (teksterne) i JSON (`metadata.json`)
- Loader index igen og kan sÃ¸ge i det

Her har jeg valgt efter valg af model.
opsat "faiss_index.idx" til at vÃ¦re stedet hvor vektor-indexet bliver gemt
og "metadata.json" til at indeholde tekst-dokumenter.

![[Pasted image 20251125001146.png]]
Bagefter bliver hvert dokument embedded  til en 384-dimensionel vektor. via modellens encoder.
Herefter  bliver filen oprettet eller indlÃ¦st og dokumenter gemmes permanent som i en DB.
Herefter er der en test query.

![[Pasted image 20251125001204.png]]
Efter kÃ¸rsel af scriptet i mit python miljÃ¸, sÃ¥ svarer modellen tilbage pÃ¥ queryen i scriptet.

Her fÃ¥r vi et svar ved at modellen opretter en embedding af teksten og gÃ¥r igennem den for at kunne sammenligne dens vektorer fra teksten vi oprettede i scriptet. Den query der bliver embedded og gemt samt brugt i RAM sÃ¥ lÃ¦nge programmet kÃ¸rer.
![[Pasted image 20251125001348.png]]
I svaret fÃ¥r vi angivet en afstand, der viser hvor relevant tekst svaret er vurderet til at vÃ¦re.
0.425... som fÃ¸rste svar gengiver er den korteste af de to tekster, men tekst nummer to er stadigvÃ¦k tÃ¦t nok pÃ¥ til at vÃ¦re vurderet af relevans i forhold til min query.


# En rigtig Vector Database Workflow**

Du har i dette projekt vist alle nÃ¸gleelementer i en fuld â€œretrieval systemâ€-pipeline:

### **âœ” Embedding af dokumenter**

â†’ Ved hjÃ¦lp af SentenceTransformer (MiniLM).

### **âœ” Gemning af embeddings permanent pÃ¥ disk**

â†’ `faiss_index.idx`  
â†’ `metadata.json`

### **âœ” Query-embedding (brugerens spÃ¸rgsmÃ¥l)**

â†’ Samme embedding-model â†’ vektor i samme rum.

### **âœ” Semantisk similarity search med FAISS**

â†’ Finder meningsmÃ¦ssigt relaterede dokumenter.

### **âœ” Returnering af top-matches med distance**

â†’ Afstand fortÃ¦ller relevans.

Dette er **hele fundamentet for RAG (Retrieval-Augmented Generation)**.

---

# ğŸ§© Hvad du har vist i dette mini-projekt

Du kan nu dokumentere, at du har bygget:

## ğŸ“ **En fuld funktionel persistent vector store med FAISS, inkl. opslag og similarity search.**

Og ikke kun in-memory â€” du har:

- persistence
    
- metadata-mapping
    
- query-pipeline
    
- semantisk rangerede resultater
    
- genindlÃ¦sning mellem sessions
    
- en Python-kodebase der ligner en â€œrigtigâ€ RAG back-end



